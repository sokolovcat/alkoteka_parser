# Тестовое задание
Используя фреймворк Scrapy необходимо написать парсер для получения информации о товарах интернет-магазина из списка категорий по заранее заданному шаблону

Информация должна быть структурирована в виде словарей согласно формату выходных данных и сохранена в файл формата json.
На вход подается список категорий в виде ссылок (минимум 3), с количеством товаров от 100 штук на категорию
на сайте alkoteka.com
 (Например: https://alkoteka.com/catalog/slaboalkogolnye-napitki-2)
Обязательно осуществлять сбор данных с учетом выбранного региона для парсинга - Краснодар
По возможности для получения информации добавить возможность использовать подключение через прокси

# Входные данные
Изменяемый список ссылок на категории, можно выполнить в одном из двух вариантов:
1.	В виде константной переменной формата: START_URLS = ["url_1", "url_2", ..., "url_3"]
2.	В виде отдельного файла, который будет содержать список ссылок в произвольном формате


# Выходные данные
Формат выходных данных для одного товара:
На следующей странице вы увидите  общий шаблон формата данных, и он не учитывает особенности сайта, выбранного для задания. 

 Если вы не смогли найти какие-то данные во время анализа сайта, все поля все равно должны быть собраны согласно стандартным значениям, так как являются обязательными для корректной проверки.

{
1:	    "timestamp": int,  # Дата и время сбора товара в формате timestamp.
2:	    "RPC": "str",  # Уникальный код товара.
3:	    "url": "str",  # Ссылка на страницу товара.
4:	    "title": "str",  # Заголовок/название товара (! Если в карточке товара указан цвет или объем, но их нет в названии, необходимо добавить их в title в формате: "{Название}, {Цвет или Объем}").
5:	    "marketing_tags": ["str"],  # Список маркетинговых тэгов, например: ['Популярный', 'Акция', 'Подарок']. Если тэг представлен в виде изображения собирать его не нужно.
6:	    "brand": "str",  # Бренд товара.
7:	    "section": ["str"],  # Иерархия разделов, например: ['Игрушки', 'Развивающие и интерактивные игрушки', 'Интерактивные игрушки'].
8:	    "price_data": {
9:	        "current": float,  # Цена со скидкой, если скидки нет то = original.
10:	        "original": float,  # Оригинальная цена.
11:	        "sale_tag": "str"  # Если есть скидка на товар то необходимо вычислить процент скидки и записать формате: "Скидка {discount_percentage}%".
12:	    },
13:	    "stock": {
14:	        "in_stock": bool,  # Есть товар в наличии в магазине или нет.
15:	        "count": int  # Если есть возможность получить информацию о количестве оставшегося товара в наличии, иначе 0.
16:	    },
17:	    "assets": {
18:	        "main_image": "str",  # Ссылка на основное изображение товара.
19:	        "set_images": ["str"],  # Список ссылок на все изображения товара.
20:	        "view360": ["str"],  # Список ссылок на изображения в формате 360.
21:	        "video": ["str"]  # Список ссылок на видео/видеообложки товара.
22:	    },
23:	    "metadata": {
24:	        "__description": "str",  # Описание товара
25:	        "KEY": "str",
26:	        "KEY": "str",
27:	        "KEY": "str"
28:	        # Также в metadata необходимо добавить все характеристики товара которые могут быть на странице.
29:	        # Например: Артикул, Код товара, Цвет, Объем, Страна производитель и т.д.
30:	        # Где KEY - наименование характеристики.
31:	    }
32:	    "variants": int,  # Кол-во вариантов у товара в карточке (За вариант считать только цвет или объем/масса. Размер у одежды или обуви варинтами не считаются).
33:	}
 
# Ожидаемый результат
Результатом выполненного задания ожидается парсер который можно запустить командой
1:	scrapy crawl spider_name -O result.json
После отработки парсера должен быть результирующий файл с собранными данными товаров по заданным категориям в формате, установленным согласно выходным данным.
Плюсом будет использование прокси (хотя бы прокидывание в запросы бесплатных прокси)
Плюсом будет сбор данных по заданному региону (могут отличаться цены, наличие и прочие данные для сайта)
Чем больше навыков Вы продемонстрируете в тестовом задании, тем лучше. (ООП/прокси/middleware)

*** Обратите внимание, что тестовое задание выполняется только на Scrapy (без использования  Playwright, Headless, Selenium и тд)

